# Machine Learning Design and Model Governance ğŸ§ 

This document presents a **unified view** of the machine learning design and model governance for the H&M Personalized Fashion Recommendation System.  
It combines architectural reasoning, training strategy, evaluation methodology, and responsible usage considerations into a single, coherent narrative.

---

## ğŸ¯ Objective

The primary objective of the system is to **retrieve relevant fashion items** for each user based on historical purchase behavior.

The problem is framed as a **top-K retrieval task**, rather than explicit rating prediction, which better aligns with large-scale retail environments where:
- feedback is implicit
- item catalogs are large
- latency requirements are strict

---

## ğŸ§  Model Architecture

The system adopts a **Two-Tower retrieval architecture**, composed of:
- a **User Tower** that encodes customer behavior and profile information
- an **Item Tower** that encodes product identity and attributes

Each tower produces a dense vector representation, and relevance is modeled as **similarity in a shared embedding space**.

This separation allows user and item representations to be:
- trained independently
- precomputed efficiently
- reused during inference

---

## ğŸ§© Input Representation

### ğŸ‘¤ User Representation
User embeddings are constructed from:
- customer_id embeddings
- aggregated interaction signals derived from transactions
- optional profile attributes sourced from the feature store

These signals capture **long-term user preferences** inferred from implicit behavior.

---

### ğŸ‘— Item Representation
Item embeddings are constructed from:
- article_id embeddings
- categorical product attributes
- stable item-level metadata

The output is a fixed-dimensional **item embedding** suitable for similarity-based retrieval.

---

## ğŸ“¥ Training Data and Signals

The model is trained using:
- historical purchase interactions
- implicit feedback derived from transactions
- processed feature tables generated by the ETL pipeline

No explicit ratings, textual reviews, or user-provided preferences are used.  
Positive examples come from observed interactions, while **negative sampling** is applied to approximate non-interactions.

---

## ğŸ” Training Strategy

Training optimizes the model to:
- increase similarity between users and items they interacted with
- decrease similarity for randomly sampled negative items

Key characteristics of the training setup:
- shared embedding space for users and items
- implicit-feedback optimization objective
- offline batch training for reproducibility

This approach prioritizes **retrieval quality and scalability** over fine-grained preference estimation.

---

## ğŸ“ Retrieval and Indexing

After training:
- all item embeddings are precomputed
- embeddings are indexed using **FAISS** for approximate nearest neighbor search

During inference:
- a user embedding is generated or retrieved
- FAISS is queried to return the top-K most similar items

This design enables **low-latency retrieval** even with a large item catalog.

---

## ğŸ“Š Evaluation Methodology

Model performance is evaluated **offline** using ranking-based metrics.

Evaluation follows a **time-aware split**:
- past interactions are used for training
- future interactions are held out for evaluation

This setup better reflects real-world recommendation scenarios where models must generalize to unseen future behavior.

---

## ğŸ§ª Evaluation Metrics

The primary evaluation metrics are:
- **Recall@K**, measuring coverage of relevant items
- **NDCG@K**, measuring ranking quality

These metrics focus on **retrieval effectiveness**, rather than exact prediction accuracy.

---

## â„ï¸ Cold-Start Strategy

Personalization depends on historical interactions.

For users with insufficient or no interaction history:
- personalized embeddings cannot be reliably constructed
- the system falls back to **popular items**

Popularity is computed from historical transaction frequency, ensuring that recommendations remain valid for new users.

---

## ğŸ”Œ Outputs and Artifacts

The outputs of the ML phase include:
- trained Two-Tower model weights
- user and item embeddings
- FAISS index
- evaluation summaries

These artifacts are stored in the **model registry** and reused during the serving and demo phase.

---

## âš ï¸ Intended Use

This model is intended for:
- personalized product retrieval
- offline evaluation and experimentation
- demo and portfolio-level deployments

It is **not intended** for automated decision-making in pricing, promotions, or business-critical systems without additional safeguards.

---

## ğŸš« Known Limitations

Key limitations of the current design include:
- offline evaluation only (no online feedback loop)
- static embeddings without real-time updates
- single-stage retrieval without re-ranking
- limited personalization for extreme cold-start users

These limitations reflect deliberate design trade-offs favoring **clarity and robustness**.

---

## ğŸ”® Future Extensions

Potential future enhancements include:
- two-stage recommendation pipelines (retrieval + ranking)
- online feedback integration
- session-aware or sequential modeling
- richer feature representations
- public deployment with scalable infrastructure

These extensions can be added incrementally without redesigning the core system.

---

## ğŸ“ Closing Notes

This document unifies **model design and model governance** into a single perspective.  
It emphasizes transparency, reproducibility, and realistic engineering trade-offs, positioning the system as a **production-inspired, portfolio-grade recommendation pipeline**.
